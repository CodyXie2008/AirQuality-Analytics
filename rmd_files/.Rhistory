quantile(project$pm25_concentration, probs = 0.75) - quantile(project$pm25_concentration, probs = 0.25)
var(project$pm25_concentration)
sd(project$pm25_concentration)
install.packages('ggplot2')
library(ggplot2)
# bar chart for year; year is integer currently, we can change to categorical (factor)
ggplot(project, aes(x = factor(year))) + geom_bar(stat = 'count', width = 0.5) + stat_count(aes(label = after_stat(count)), vjust = -0.5, geom = 'text') + ylim(0, 350)
# histogram for PM2.5 across both countries
ggplot(project, aes(x = pm25_concentration)) + geom_histogram(bins = 25) + stat_bin(aes(label = after_stat(count)), bins = 25, vjust = -0.5, geom = 'text') + ylim(0, 300)
# dotplot for how PM10 is distributed across different years
# make sure you convert year to a factor
ggplot(project) + geom_dotplot(aes(x = factor(year), y = pm10_concentration), binaxis = 'y', stackdir = 'center', stackratio = 0)
# boxplot for how PM10 distribution varies between the two countries
ggplot(project) + geom_boxplot(aes(x = country_name, y = pm10_concentration))
# scatterplot
ggplot(project) + geom_point(aes(x = pm10_concentration, y = pm25_concentration), color = 'blue')
# also use country as a way to differentiate the points
ggplot(project) + geom_point(aes(x = pm10_concentration, y = pm25_concentration, color = country_name))
# two sample t test for our project
# let's say we hypothesise that AQ in Germany is worse than
# France. Is this true?
t.test(germany_df$pm25_concentration, france_df$pm25_concentration, alternative = 'greater')
# change the data source to germany_df or france_df for
# country-specific model
project_lm <- lm(pm25_concentration ~ pm10_concentration, project)
coef(project_lm)
pm25_prediction <- data.frame(pm10_concentration = c(40, 50, 60))
pm25_prediction
# using our model for predictions
pm25_prediction$prediction <- predict(project_lm, pm25_prediction)
pm25_prediction
# visualising our model
ggplot(project, aes(x = pm10_concentration, y = pm25_concentration)) + geom_point(color = 'blue') + geom_smooth(se = TRUE, method = lm, color = 'red')
# doing the hypothesis test for our model
summary(project_lm)
# compute residuals and fitted values
project$residuals <- residuals(project_lm)
project$fitted <- fitted(project_lm)
head(project)
# plot the normal probabiity plot
qqnorm(project$residuals)
qqline(project$residuals, col = 'steelblue', lwd = 2)
# e vs y^
plot(x = project$fitted, y = project$residuals)
# e vs x
plot(x = project$pm10_concentration, y = project$residuals)
# e vs time
plot(x = project$year, y = project$residuals)
# adding NO2 concentration as an additional predictor
project_mlr <- lm(pm25_concentration ~ pm10_concentration + no2_concentration, data = project)
coef(project_mlr)
# using our model for predictions
mlr_predictions <- data.frame(pm10_concentration = c(40, 50, 60),
no2_concentration = c(60, 40, 30))
mlr_predictions$predictions <- predict(project_mlr, mlr_predictions)
mlr_predictions
# doing the hypothesis test
summary(project_mlr)
# checking for multicollinearity
install.packages('car')
library(car)
vif(project_mlr)
install.packages("dplyr")
install.packages("car")
install.packages("ggplot2")
dir()
# load in the dataset
project <- read.csv("WHO_DB_FR_GER_cleaned_2024.csv")
head(project)
# load in the dataset
project1 <- read.csv("WHO_DB_FR_GER_cleaned_2024.csv")
head(project)
# exploring, getting mean and median
summary(project)
# load in the dataset
project <- read.csv("WHO_DB_FR_GER_cleaned_2024.csv")
head(project1)
# load in the dataset
project <- read.csv("WHO_DB_FR_GER_cleaned_2024.csv")
head(project1)
# exploring, getting mean and median
summary(project)
# load in the dataset
project <- read.csv("WHO_DB_FR_GER_cleaned_2024.csv")
head(project)
# exploring, getting mean and median
summary(project)
# if we just want the dataset for one country
# filtering for Germany
germany_df <- project[(project$country_name == "Germany"),]
summary(germany_df)
# load in the dataset
project <- read.csv("WHO_DB_FR_GER_cleaned_2024.csv")
head(project)
# exploring, getting mean and median
summary(project)
# if we just want the dataset for one country
# filtering for Germany
germany_df <- project[(project$country_name == "Germany"),]
summary(germany_df)
# filtering for France
france_df <- project[(project$country_name == 'France'),]
summary(france_df)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
mean(project$pm25_concentration)
# filtering for France
france_df <- project[(project$country_name == 'France'),]
summary(france_df)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
mean(project$pm25_concentration)
# exploring, getting mean and median
summary(project)
# overall median PM10
median(project$pm10_concentration)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
france_df <- project[(project$country_name == 'France'),]
mean(project$pm25_concentration)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
mean(project$pm25_concentration)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
france_df <- project[(project$country_name == 'France'),]
mean(project$pm25_concentration)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
mean(projec$pm25_concentration)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
mean(project$pm25_concentration)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
mean(project$country_name == 'France',pm25_concentration)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
mean(project$country_name == 'France'pm25_concentration)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
mean(project$country_name == 'France'$pm25_concentration)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
mean(france_df$pm25_concentration)
# filtering for France
france_df <- project[(project$country_name == 'France'),]
summary(france_df)
# overall median PM10
median(project$pm10_concentration)
# or france_df for country-specific mean
mean(france_df$pm25_concentration)
# filtering for France
france_df <- project[(project$country_name == 'France'),]
summary(france_df)
# or france_df for country-specific mean
Min(france_df$pm25_concentration)
# or france_df for country-specific mean
min(france_df$pm25_concentration)
install.packages('dplyr')
install.packages('dplyr')
library(dplyr)
project$pm25_concentration %>% log() %>% mean() %>% exp %>% round(1)
install.packages('dplyr')
library(dplyr)
project$pm25_concentration %>% log() %>% mean() %>% exp %>% round(1)
range(project$pm25_concentration)
max(project$pm25_concentration) - min(project$pm25_concentration)
quantile(project$pm25_concentration, probs = c(0.25, 0.75))
# compute the IQR
quantile(project$pm25_concentration, probs = 0.75) - quantile(project$pm25_concentration, probs = 0.25)
var(project$pm25_concentration)
sd(project$pm25_concentration)
# bar chart for year; year is integer currently, we can change to categorical (factor)
ggplot(project, aes(x = factor(year))) + geom_bar(stat = 'count', width = 0.5) + stat_count(aes(label = after_stat(count)), vjust = -0.5, geom = 'text') + ylim(0, 350)
install.packages('ggplot2')
library(ggplot2)
# bar chart for year; year is integer currently, we can change to categorical (factor)
ggplot(project, aes(x = factor(year))) + geom_bar(stat = 'count', width = 0.5) + stat_count(aes(label = after_stat(count)), vjust = -0.5, geom = 'text') + ylim(0, 350)
# histogram for PM2.5 across both countries
ggplot(project, aes(x = pm25_concentration)) + geom_histogram(bins = 25) + stat_bin(aes(label = after_stat(count)), bins = 25, vjust = -0.5, geom = 'text') + ylim(0, 300)
# bar chart for year; year is integer currently, we can change to categorical (factor)
ggplot(project, aes(x = factor(year))) + geom_bar(stat = 'count', width = 1.5) + stat_count(aes(label = after_stat(count)), vjust = -0.5, geom = 'text') + ylim(0, 350)
# bar chart for year; year is integer currently, we can change to categorical (factor)
ggplot(project, aes(x = factor(year))) + geom_bar(stat = 'count', width = 0.5) + stat_count(aes(label = after_stat(count)), vjust = -0.5, geom = 'text') + ylim(0, 350)
# dotplot for how PM10 is distributed across different years
# make sure you convert year to a factor
ggplot(project) + geom_dotplot(aes(x = factor(year), y = pm10_concentration), binaxis = 'y', stackdir = 'center', stackratio = 0)
dir()
# load in the dataset
project <- read.csv("WHO_DB_FR_GER_cleaned_2024.csv")
head(project)
# exploring, getting mean and median
summary(project)
# if we just want the dataset for one country
# filtering for Germany
germany_df <- project[(project$country_name == "Germany"),]
summary(germany_df)
# filtering for France
france_df <- project[(project$country_name == 'France'),]
summary(france_df)
# overall mean for entire dataset for PM2.5; substitute with germany_df
# or france_df for country-specific mean
mean(project$pm25_concentration)
# or france_df for country-specific mean
mean(france_df$pm25_concentration)
# or france_df for country-specific min
min(france_df$pm25_concentration)
# overall median PM10
median(project$pm10_concentration)
install.packages('dplyr')
library(dplyr)
project$pm25_concentration %>% log() %>% mean() %>% exp %>% round(1)
range(project$pm25_concentration)
max(project$pm25_concentration) - min(project$pm25_concentration)
quantile(project$pm25_concentration, probs = c(0.25, 0.75))
# compute the IQR
quantile(project$pm25_concentration, probs = 0.75) - quantile(project$pm25_concentration, probs = 0.25)
var(project$pm25_concentration)
sd(project$pm25_concentration)
install.packages('ggplot2')
library(ggplot2)
# bar chart for year; year is integer currently, we can change to categorical (factor)
ggplot(project, aes(x = factor(year))) + geom_bar(stat = 'count', width = 0.5) + stat_count(aes(label = after_stat(count)), vjust = -0.5, geom = 'text') + ylim(0, 350)
# histogram for PM2.5 across both countries
ggplot(project, aes(x = pm25_concentration)) + geom_histogram(bins = 25) + stat_bin(aes(label = after_stat(count)), bins = 25, vjust = -0.5, geom = 'text') + ylim(0, 300)
# dotplot for how PM10 is distributed across different years
# make sure you convert year to a factor
ggplot(project) + geom_dotplot(aes(x = factor(year), y = pm10_concentration), binaxis = 'y', stackdir = 'center', stackratio = 0)
# boxplot for how PM10 distribution varies between the two countries
ggplot(project) + geom_boxplot(aes(x = country_name, y = pm10_concentration))
# scatterplot
ggplot(project) + geom_point(aes(x = pm10_concentration, y = pm25_concentration), color = 'blue')
# also use country as a way to differentiate the points
ggplot(project) + geom_point(aes(x = pm10_concentration, y = pm25_concentration, color = country_name))
# two sample t test for our project
# let's say we hypothesise that AQ in Germany is worse than
# France. Is this true?
t.test(germany_df$pm25_concentration, france_df$pm25_concentration, alternative = 'greater')
# change the data source to germany_df or france_df for
# country-specific model
project_lm <- lm(pm25_concentration ~ pm10_concentration, project)
coef(project_lm)
pm25_prediction <- data.frame(pm10_concentration = c(40, 50, 60))
pm25_prediction
# using our model for predictions
pm25_prediction$prediction <- predict(project_lm, pm25_prediction)
pm25_prediction
# visualising our model
ggplot(project, aes(x = pm10_concentration, y = pm25_concentration)) + geom_point(color = 'blue') + geom_smooth(se = TRUE, method = lm, color = 'red')
# doing the hypothesis test for our model
summary(project_lm)
# compute residuals and fitted values
project$residuals <- residuals(project_lm)
project$fitted <- fitted(project_lm)
head(project)
# plot the normal probabiity plot
qqnorm(project$residuals)
qqline(project$residuals, col = 'steelblue', lwd = 2)
# e vs y^
plot(x = project$fitted, y = project$residuals)
# e vs x
plot(x = project$pm10_concentration, y = project$residuals)
# e vs time
plot(x = project$year, y = project$residuals)
# adding NO2 concentration as an additional predictor
project_mlr <- lm(pm25_concentration ~ pm10_concentration + no2_concentration, data = project)
coef(project_mlr)
# using our model for predictions
mlr_predictions <- data.frame(pm10_concentration = c(40, 50, 60),
no2_concentration = c(60, 40, 30))
mlr_predictions$predictions <- predict(project_mlr, mlr_predictions)
mlr_predictions
# doing the hypothesis test
summary(project_mlr)
# checking for multicollinearity
install.packages('car')
library(car)
vif(project_mlr)
dir()
resales_df <- read.csv("resale-sample-small.csv")
resales_df
library(ggplot2)
ggplot(resales_df, aes(x = floor_area_sqm, y = resale_price)) + geom_point(color = 'blue')
fit.lm <- lm(resale_price ~ floor_area_sqm, resales_df)
coef(fit.lm)
resale_prediction <- data.frame(floor_area_sqm = c(74, 69, 102))
resale_prediction
resale_prediction$prediction <- predict(fit.lm, resale_prediction)
resale_prediction
ggplot(resales_df, aes(x = floor_area_sqm, y = resale_price)) + geom_point(color = 'blue') + geom_smooth(se = FALSE, method = lm, color = 'red')
summary(fit.lm)
resales_df$residuals <- residuals(fit.lm)
resales_df
resales_df$fitted <- fitted(fit.lm)
resales_df
install.packages('zoo')
library(zoo)
resales_df$actual_month <- as.yearmon(resales_df$month)
resales_df
qqnorm(resales_df$residuals)
qqline(resales_df$residuals, col = 'steelblue', lwd = 2)
plot(x = resales_df$fitted, y = resales_df$residuals)
plot(x = resales_df$floor_area_sqm, y = resales_df$residuals)
plot(x = resales_df$actual_month, y = resales_df$residuals)
cor(x = resales_df$floor_area_sqm, y = resales_df$resale_price)
resales_df$year_of_sale <- as.numeric(substr(resales_df$month, 1, 4))
head(resales_df)
resales_df$remaining_lease <- 99- (resales_df$year_of_sale - resales_df$lease_commence_date)
resales_df
mlr.fit <- lm(resale_price ~ floor_area_sqm + remaining_lease, data = resales_df)
coef(mlr.fit)
resale_predictions <- data.frame(floor_area_sqm = c(74, 69, 102),
remaining_lease = c(65, 73, 84))
resale_predictions$predictions <- predict(mlr.fit, resale_predictions)
resale_predictions
summary(mlr.fit)
install.packages('car')
library(car)
vif(mlr.fit)
mlr.fit2 <- lm(resale_price ~ floor_area_sqm + remaining_lease +
lease_commence_date, data = resales_df)
vif(mlr.fit2)
psi_df <- read_excel("PSI.xlsx", sheet = "Sheet1")
psi_df <- read_excel("PSI.xlsx", sheet = "Sheet1")
psi_df <- read_excel("PSI.xlsx", sheet = "Sheet1")
dir()
join_df_full <- read.csv("join_df_full.csv")
head(join_df_full)
summary(join_df_full)
mean(join_df_full$SO2)
median(join_df_full$SO2)
(prod(join_df_full$SO2)) ** (1 / length(join_df_full$SO2))
# the above won't work for large datasets, with many rows
# the following is an alternative
install.packages('dplyr')
library(dplyr)
join_df_full$SO2 %>% log() %>% mean() %>% exp() %>% round(1)
install.packages('modeest')
library(modeest)
mfv(join_df_full$SO2)
range(join_df_full$PSI)
max(join_df_full$PSI) - min(join_df_full$PSI)
quantile(join_df_full$PSI, probs = c(0.25, 0.75))
var(join_df_full$PSI)
sqrt(var(join_df_full$PSI))
sd(join_df_full$PSI)
(prod(join_df_full$SO2)) ** (1 / length(join_df_full$SO2))
# the above won't work for large datasets, with many rows
# the following is an alternative
install.packages('dplyr')
library(dplyr)
mfv(join_df_full$SO2)
dir()
join_df_full <- read.csv("join_df_full.csv")
head(join_df_full)
summary(join_df_full)
mean(join_df_full$SO2)
median(join_df_full$SO2)
(prod(join_df_full$SO2)) ** (1 / length(join_df_full$SO2))
# the above won't work for large datasets, with many rows
# the following is an alternative
install.packages('dplyr')
library(dplyr)
join_df_full$SO2 %>% log() %>% mean() %>% exp() %>% round(1)
install.packages('modeest')
library(modeest)
mfv(join_df_full$SO2)
range(join_df_full$PSI)
max(join_df_full$PSI) - min(join_df_full$PSI)
quantile(join_df_full$PSI, probs = c(0.25, 0.75))
var(join_df_full$PSI)
sqrt(var(join_df_full$PSI))
sd(join_df_full$PSI)
# 查看当前工作目录中的文件列表
# 确认数据文件是否存在
# 输出：显示当前目录下的所有文件和文件夹
dir()
# 读取空气质量数据文件
# join_df_full.csv 包含多种空气质量指标数据
join_df_full <- read.csv("join_df_full.csv")
# 查看数据的前6行，了解数据结构
# 显示变量名、数据类型和示例值
head(join_df_full)
# 生成数据框的全面统计摘要
# 对于数值变量：显示最小值、Q1、中位数、均值、Q3、最大值
# 对于分类变量：显示频数统计
summary(join_df_full)
# 计算SO2浓度的算术平均值
# 均值对异常值敏感，受极端值影响较大
mean(join_df_full$SO2)
# 计算SO2浓度的中位数（50%分位数）
# 中位数对异常值不敏感，更能代表数据的中心位置
median(join_df_full$SO2)
# 尝试计算SO2浓度的几何平均数（方法1）
# 公式：几何平均数 = (所有值的乘积)^(1/观测值数量)
# 问题：对于大数据集，这种方法可能导致数值溢出
(prod(join_df_full$SO2)) ** (1 / length(join_df_full$SO2))
# 注释说明前一种方法的局限性
# 安装并加载dplyr包用于数据处理
# the above won't work for large datasets, with many rows
# the following is an alternative
install.packages('dplyr')
library(dplyr)
# 使用改进的方法计算几何平均数（方法2）
# 步骤：取对数 → 计算均值 → 取指数 → 四舍五入
# 公式：几何平均数 = exp(mean(log(x)))
# 这种方法数值稳定，适用于大数据集
join_df_full$SO2 %>% log() %>% mean() %>% exp() %>% round(1)
# 安装并加载modeest包，专门用于计算众数
install.packages('modeest')
library(modeest)
# 计算SO2浓度的众数（最频繁出现的值）
# mfv = most frequent value
# 对于连续型数据，众数可能不明显或不存在
mfv(join_df_full$SO2)
# 计算PSI值的范围（最小值和最大值）
# 输出：包含最小值和最大值的向量
range(join_df_full$PSI)
# 手动计算PSI值的极差（最大值 - 最小值）
# 极差是最简单的离散程度度量，但受异常值影响大
max(join_df_full$PSI) - min(join_df_full$PSI)
# 计算PSI值的四分位数
# probs参数指定要计算的分位数
# 这里计算第25百分位数（Q1）和第75百分位数（Q3）
# 四分位距（IQR） = Q3 - Q1，用于识别异常值
quantile(join_df_full$PSI, probs = c(0.25, 0.75))
# 计算PSI值的样本方差
# 公式：方差 = Σ(xᵢ - x̄)² / (n-1)
# 方差衡量数据点与均值的平均平方距离
# 单位是原始单位的平方
var(join_df_full$PSI)
# 通过对方差取平方根来计算标准差
# 标准差 = 方差的平方根
# 单位与原始数据相同，更易于解释
sqrt(var(join_df_full$PSI))
# 直接使用内置函数计算标准差
# 结果与 sqrt(var(join_df_full$PSI)) 完全相同
# 标准差是描述数据离散程度最常用的统计量
sd(join_df_full$PSI)
# 空代码块，可用于添加额外的分析或可视化
# 例如：创建直方图、箱线图等可视化图表
install.packages("modeest")
install.packages("dplyr")
# 查看当前工作目录中的文件列表
# 确认数据文件是否存在
# 输出：显示当前目录下的所有文件和文件夹
dir()
# 读取空气质量数据文件
# join_df_full.csv 包含多种空气质量指标数据
join_df_full <- read.csv("join_df_full.csv")
# 查看数据的前6行，了解数据结构
# 显示变量名、数据类型和示例值
head(join_df_full)
# 生成数据框的全面统计摘要
# 对于数值变量：显示最小值、Q1、中位数、均值、Q3、最大值
# 对于分类变量：显示频数统计
summary(join_df_full)
# 计算SO2浓度的算术平均值
# 均值对异常值敏感，受极端值影响较大
mean(join_df_full$SO2)
# 计算SO2浓度的中位数（50%分位数）
# 中位数对异常值不敏感，更能代表数据的中心位置
median(join_df_full$SO2)
# 尝试计算SO2浓度的几何平均数（方法1）
# 公式：几何平均数 = (所有值的乘积)^(1/观测值数量)
# 问题：对于大数据集，这种方法可能导致数值溢出
(prod(join_df_full$SO2)) ** (1 / length(join_df_full$SO2))
# 注释说明前一种方法的局限性
# 安装并加载dplyr包用于数据处理
# the above won't work for large datasets, with many rows
# the following is an alternative
install.packages('dplyr')
library(dplyr)
# 使用改进的方法计算几何平均数（方法2）
# 步骤：取对数 → 计算均值 → 取指数 → 四舍五入
# 公式：几何平均数 = exp(mean(log(x)))
# 这种方法数值稳定，适用于大数据集
join_df_full$SO2 %>% log() %>% mean() %>% exp() %>% round(1)
# 安装并加载modeest包，专门用于计算众数
install.packages('modeest')
library(modeest)
# 计算SO2浓度的众数（最频繁出现的值）
# mfv = most frequent value
# 对于连续型数据，众数可能不明显或不存在
mfv(join_df_full$SO2)
# 计算PSI值的范围（最小值和最大值）
# 输出：包含最小值和最大值的向量
range(join_df_full$PSI)
# 手动计算PSI值的极差（最大值 - 最小值）
# 极差是最简单的离散程度度量，但受异常值影响大
max(join_df_full$PSI) - min(join_df_full$PSI)
# 计算PSI值的四分位数
# probs参数指定要计算的分位数
# 这里计算第25百分位数（Q1）和第75百分位数（Q3）
# 四分位距（IQR） = Q3 - Q1，用于识别异常值
quantile(join_df_full$PSI, probs = c(0.25, 0.75))
# 计算PSI值的样本方差
# 公式：方差 = Σ(xᵢ - x̄)² / (n-1)
# 方差衡量数据点与均值的平均平方距离
# 单位是原始单位的平方
var(join_df_full$PSI)
# 通过对方差取平方根来计算标准差
# 标准差 = 方差的平方根
# 单位与原始数据相同，更易于解释
sqrt(var(join_df_full$PSI))
# 直接使用内置函数计算标准差
# 结果与 sqrt(var(join_df_full$PSI)) 完全相同
# 标准差是描述数据离散程度最常用的统计量
sd(join_df_full$PSI)
# 空代码块，可用于添加额外的分析或可视化
# 例如：创建直方图、箱线图等可视化图表
